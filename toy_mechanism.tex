\documentclass{article}
\usepackage{graphicx}
\begin{document}
\title{Proposal for a toy mechanism to prevent database reconstruction and
evaluate the amount of noise to add.}
\maketitle

\section{Problems}

\begin{enumerate}

\item Traditional mechanisms such as cell suppression, generalization
(coarsening), and top-coding do not create sufficient uncertainty to
prevent reconstruction. Instead, publications of tabular data should
incorporate noise to prevent database reconstruction.

\item Differential privacy mechanisms tell provide two things: the \emph{kind} of noise
to add, and the \emph{amount} of noise to add.

\item Although most Differential Privacy mechanisms rely on Laplace
noise, it's easier to model the error introduced by the privacy
mechanism when using Gaussian noise. Because Laplace noise has broader
tails, using Gaussian noise will result with less accuracy for the
same level of privacy.

\item Using a differential privacy mechanism requires being able to
calculate the sensitivity of a query. This is easy to do for counting
queries (the sensitivity is 1), but it's hard to do for complex
queries involving regressions, and it's not valuable when using
queries that involve potentially unbounded variables such as wealth or
income. 

\item Differential privacy mechanisms cannot be based upon an examination
of the raw data, yet examining the raw data may be the easiest way to
infer the sensitivity of a query.

\end{enumerate}

\section{Proposed mechanism}

\begin{enumerate}
\item We propose an \emph{ad hoc} privacy protection mechanism that is based on
the intuition of differential privacy but which allows relatively
straightforward deployment for publishing legacy tables.

\item In general, the mechanism will be applied directly to the
publication tables, ideally without concern for the underlying
calculations.

\item The amount of noise $g$ to added to values will be:

\begin{equation}
g = \Delta(f) \times G(1/\epsilon)
\end{equation}

Where $G(1/\epsilon)$ is Gaussian noise for a value of $\epsilon$ and
$\Delta(f)$ is the sensitivity of the query.

\item For count data, $\Delta(f)=1$. 

\item For non-count data, $\Delta(f)$ will be determined for each
  published statistic. The value shall be determined by establishing a
  bottom code 
  and a top code for all input variables and performing a
  systematic exploration of the statistic's range by adding a
  hypothetical additional data element to the current data set. 

\end{enumerate}

\subsection{An Example}

For example, consider a hypothetical example of a researcher who
wishes to publish regression statistics between family income and
grades in a hypothetical small classroom. The classroom has four
students in it. Here is the raw data:

\input{toy_regression_data.tex}

Using numpy's linear regression tool, we can calculate a linear
regression on these data, as shown in Figure~\ref{unprotected}.

\begin{figure}
\includegraphics[width=.9\linewidth]{toy_regression.pdf}
\caption{The unprotected regression.}\label{unprotected}
\end{figure}

Traditional protections include rounding of output variables (to 4
significant figures) and top-coding. In the example below, we top-code
income to \$100,000 and then round output statistics. The regression
line is drawn using the rounded values, as shown in Figure~\ref{protected1}.

\begin{figure}
\includegraphics[width=.9\linewidth]{toy_regression_rounded.pdf}
\caption{The regression, protected with top-coding and
  rounding.}\label{protected1}
\end{figure}

Instead, our proposed mechanism recomputes the regression four times,
each time adding a different extreme data point. These data points are
chosen to exercise the limits of the regression variables:

\input{toy_regression_extreme_data}

This produces four sets of regression parameters, all plotted on
the same graph in Figure~\ref{protected2}.

\begin{figure}
\includegraphics[width=.9\linewidth]{toy_regression_bounds.pdf}
\caption{Four possible regressions made with the data from
  Figure~\ref{protected1}, each one with the addition of a single data
  point that is at one of the dimensional extremes. Note that
  producing this graph requires choosing a top-code for income, but
  not for grades, because grades are bounded and (hopefully) do not
  need to be top-coded to protect privacy.}\label{protected2}
\end{figure}

We can now automatically compute the range of the regression
parameters $b_1$ and $b_0$ which are \Gzero{} and \Gone. Using Gaussian noise, we can compute 
privacy-protected values of these variables, as well as $n$ (the
sample size), for different values of $\epsilon$. 

Note that $G_n$ is the amount of Gaussian noise added to the $n$,
where:

\begin{equation}
G_n = \texttt{np.random.normal}(\texttt{scale}=1/\epsilon) / n
\end{equation}

Note that $G_1$ is the amount of Gaussian noise added to the slope,
where:

\begin{equation}
G_1 = \texttt{np.random.normal}(\texttt{scale}=b_1/\epsilon) / n
\end{equation}

Note that $G_0$ is the amount of Gaussian noise added to the
y-intercept ($b$) where:

\begin{equation}
G_0 = \texttt{np.random.normal}(\texttt{scale}=b_0/\epsilon) / n
\end{equation}



{\small\noindent
\input{toy_regression_results.tex}
}

Of course, only the values for a single epsilon may be reported, and
the errors between the reported values and the true values may not be reported. 

This white paper does not currently discussion the mechanism for
computing epsilon. 

\end{document}
