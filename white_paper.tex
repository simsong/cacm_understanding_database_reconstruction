\documentclass[5p,times,11pt]{elsarticle}
\makeatletter
\def\ps@pprintTitle{%
 \def\@oddfoot{\centerline{\thepage}}%
 \let\@evenfoot\@oddfoot}
\makeatother
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{siunitx}


\begin{document}
\begin{frontmatter}
\title{Analysis of a Database Reconstruction Attack on Public Data}

\author{Christian Martindale and Simson Garfinkel}
\address{Center for Disclosure Avoidance, U.S. Census Bureau}

\begin{abstract}
In recent years, a certain type of attack on confidential survey data,
the database reconstruction attack, has become increasingly feasible due to advances in computing power and the sophistication of general purpose problem solvers. We discuss how these attacks
function and demonstrate their effectiveness and efficiency. By applying database reconstruction techniques on statistical tables drawn from simulated data, we demonstrate that traditional disclosure avoidance techniques are often insufficient to fully protect respondent privacy, and also demonstrate that noise addition is effective at defending against database attacks by SAT solvers.
\end{abstract}


\begin{keyword}
database reconstruction attack, SAT solver, privacy, disclosure avoidance
\end{keyword}
\end{frontmatter}


\section{Problem Background}
Database intruders seek to identify individuals from publicly
available data products such as tables and graphs.
Defending against such attacks is
a priority for statistical agencies, and so researchers
have developed a variety of techniques to prevent database users
from identifying any individual's personal information.

These techniques include:
\begin{enumerate}
  \item \textbf{Cell Suppression}, where the values of cells with small counts or few possible
        generating combinations are removed from the published table
  \item \textbf{Row Swapping}, where the data rows corresponding to individuals
        with similar values in certain key cells are switched
  \item \textbf{Generalization}, where numerical values are grouped into
        buckets corresponding to ranges, instead of giving the exact
        values for each entry in the table
  \item \textbf{Top-and-bottom-coding}, where the statistical groups at the high and low ends
        of the table are given without upper or lower bound (e.g.
        reporting the highest group for age as 80+ instead of
        80-90 and 90-100)
\end{enumerate}

The goal of a database reconstruction attack is to
use public statistics released about confidential data to create a mathematical system of equations,
which then can be used to reconstruct the original data set.
While the above techniques are not without merit, this paper
demonstrates that they are insufficient in guarding data against
a modern DRA.

\section{Related Work}


In this section we examine the most relevant literature regarding the DRA.

\subsection{Noise Addition and Query Restriction}
A statistical table can be formally viewed as a set of queries applied to a series of confidential data. Dinur and Nissim \cite{noise} proposed in 2003 that seemingly innocuous queries to a statistical database could be used to compromise individuals' confidential data through obtaining indirectly identifying information. They further demonstrated that restricting the number or type of queries is often insufficient to prevent access to indirectly identifying information, since the system's refusal to answer a 'dangerous' query itself gives the user information. The authors found that if a database is modeled as a string of $n$ bits, then at least $\sqrt{n}$ bits must be modified by adding noise to protect individuals from being identified.


\subsection{Linear Reconstruction}

Kasiviswanathan, Rudelson, and Smith \cite{linearattack} introduced the concept of the linear reconstruction attack which is the root behind the generic DRA. The key in this paper is the concept that, when given nonsensitive data such as zip code or gender, an attacker can construct a matrix of linear equalities which can often be solved in polynomial time. The paper also analyzes a common reconstruction technique known as least squares decoding, where the attacker sets up a goal function to minimize the square of the distance between two databases in order to reconstruct the original database. Although the modern DRA is much more powerful due to solvers' abilities to support constraints besides simple equalities, the core concept of the matrix construction from this paper is still applicable.

\subsection{Identifying Properties of a Database from Published Statistics}
Brown and Heathers \cite{grim} developed the granularity-related inconsistency of means (GRIM) test in response to observed inconsistencies in published data from psychological journals. This test is centered around the premise that, for statistics drawn from integer data, only certain means are possible. The GRIM test determines whether reported means could possibly have come from data sets with a certain size, granularity, and group number. In surveying 71 published articles, the authors found 36 papers with one inconsistency and 16 with two or more inconsistencies. Although this test was intended to detect possible errors or mean falsification in published articles, the concept of drawing inferential conclusions about a data set based only off of published statistics is a key concept behind the DRA.



\section{The Database Reconstruction Attack: An Example}


To conceptually understand a DRA, we first consider a survey given to two households by a statistical agency. Table~\ref{groundtruthsmall} shows a hypothetical survey and responses from a small population.

The statistical agency then publishes the data product in Table~\ref{publishedstatsbig} based on the survey results. If information in a cell comes from only one individual, then that cell is suppressed to protect that individual's privacy.
Retabulating these results in a numerical format with the keys in Table~\ref{tabulationkey} gives the results in Table~\ref{resultsbig}.


\begin{table*}[t]

\begin{minipage}[t]{\columnwidth}
\begin{tabular}{rlll}
Age & Sex & Race & Gen \\
\hline
80 & Female & Black & Grandparent\\
40 & Male & White & Parent\\
70 & Female & White & Grandparent\\
30 & Female & Black & Parent\\
90 & Male & White & Grandparent\\
\hline
\end{tabular}
\caption{Responses from a single fictional household
to the survey: \textbf{Please provide the following for each member of your family: Age, Sex, Race, Generation.} (Not published)} \label{groundtruthsmall}
\end{minipage}
\hspace{\columnsep}
\begin{minipage}[t]{\columnwidth}
\begin{tabular}{rlll}
Age & Sex & Race & Gen \\
\hline
10 & Male & Black & Child\\
10 & Male & Black & Child\\
10 & Female & White & Child\\
40 & Female & White & Parent\\
20 & Male & Black & Parent\\
\hline
\end{tabular}
\caption{Responses from a different fictional household
to the survey from Table \ref{groundtruthsmall} (Not published)} \label{groundtruth2}
\end{minipage}
\end{table*}


\begin{table*}[t]

\begin{minipage}[t]{\columnwidth}
\begin{tabular}{c|c|c|c|c|c}
ID & Household & Age & Sex & Race & Generation \\
\hline
1 & H1 & A1 & S1 & R1 & G1  \\
2 & H2 & A2 & S2 & R2 & G2  \\
3 & H3 & A3 & S3 & R3 & G3  \\
4 & H4 & A4 & S4 & R4 & G4  \\
5 & H5 & A5 & S5 & R5 & G5  \\
6 & H6 & A6 & S6 & R6 & G6  \\
7 & H7 & A7 & S7 & R7 & G7  \\
8 & H8 & A8 & S8 & R8 & G8  \\
9 & H9 & A9 & S9 & R9 & G9  \\
10 & H10 & A10 & S10 & R10 & G10  \\
\hline
\end{tabular}
\caption{DRA unknowns}
\label{unknownssmall}
\end{minipage}

\begin{minipage}[t]{\columnwidth}
\begin{tabular}{c|c|c|c|c|c}
ID & Household & Age & Sex & Race & Generation \\
\hline
1 & 1 & 80 & 1 & 1 & 2  \\
2 & 1 & 40 & 0 & 0 & 1  \\
3 & 1 & 70 & 1 & 0 & 2  \\
4 & 1 & 30 & 1 & 1 & 1  \\
5 & 1 & 90 & 0 & 0 & 2  \\
6 & 2 & 10 & 0 & 1 & 0  \\
7 & 2 & 10 & 0 & 1 & 0  \\
8 & 2 & 10 & 1 & 0 & 0  \\
9 & 2 & 40 & 1 & 0 & 1 \\
10 & 2 & 20 & 0 & 1 & 1 \\
\hline
\end{tabular}
\caption{Survey results}
\label{resultsbig}
\end{minipage}
\end{table*}

\begin{table}
\begin{tabular}{c|c}
Key & Value \\
\hline
Male & 0 \\
Female & 1 \\
White & 0 \\
Black & 1 \\
Child & 0 \\
Parent & 1 \\
Grandparent & 2 \\
\hline
\end{tabular}
\caption{Tabulation key}\label{tabulationkey}
\end{table}


\begin{table}[t]
\begin{tabular}{cc|c}
A & B & A==B  \\
\hline
True & True & 1   \\
True & False & 0  \\
False & True & 0  \\
False & False & 1  \\
\hline
\end{tabular}
\caption{Truth table for the == operator}\label{truthtable}
\end{table}


 To start, the attacker writes the table of 50 unknowns given in Table~\ref{unknownssmall}, with the goal of reconstructing the database in Table~\ref{resultsbig}.



The reconstruction attack works by identifying constraint
equations given by the data table. Constraint equations are  mathematical formulae representing rules that the ground truth satisfies. Next we discuss two constraints.
\subsection{Constraint 1}
\textbf{Individuals: Number = 10, Average Age = 40}


This can be written as a linear constraint equation using the symbols for age, $A1...A10$ given in Table~\ref{unknownssmall}:
\[\frac{A1 + A2 + A3 + A4 +...+ A10}{10} = 40\]

This equation is in 10 unknowns, and so has many possible solutions alone.
However, the attacker can write more constraint equations to further constrain the values of the unknowns.

Here, the == operator is a test for equivalence.It returns 1 if the left and right hand sides are equal, and 0 otherwise. A truth table for this operator is shown in Table~\ref{truthtable}. Additionally, the = operator is used to show that the right-hand side and left-hand side of this operator must be equal.

\subsection{Constraint 2}
\textbf{Children: Number = 3, Average Age = 10}


Becomes the following two equations:

\begin{align*}
& (G1==0) + (G2==0) + (G3==0)+\\
& (G4==0)+...+(G10==0) = 3
\end{align*}
\begin{align*}
&  A1 * (G1==0) + \\
&  A2 * (G2==0) + A3 * (G3==0) +\\
&  A4 * (G4==0) +...+ A10 * (G10==0) = 10
\end{align*}

\subsection{Filling in the Remaining Constraints}
Once the attacker has converted all the published statistics
into equations like the ones above, the equations together form a system of many equations in 50 unknowns. This system has one true solution, equivalent to the
ground truth, and possibly many other false solutions, which fit the constraints but are not equivalent to the ground truth.
The \textit{solution universe}, the set of all solutions that fit the encoded set of constraints, is potentially quite large, containing many false solutions along with the true solution.
However, each time the agency publishes a new statistic, the attacker can generate new constraints and therefore narrow
down the set of possible solutions.

Eventually, the attacker
will be able to narrow down the solution universe to just one solution, at which point the solution universe contains only
the ground truth. At this point, the attack has succeeded, and the statistical agency has completely failed to protect its respondents' privacy. Note that the cell suppression disclosure avoidance technique does not prevent the attacker from performing the reconstruction attack, but rather simply gives one fewer constraint to work with per cell suppressed.

Furthermore, even if the number of constraints is insufficient to narrow down the solution universe to just one element, the attacker can still often identify personal data for some respondents because of the high probability that all remaining solutions share values for a set of people. For example, if there are three remaining solutions in the solution universe, and all three contain a 75-year-old black male grandparent in household 1, then the attacker knows that this person is a real person in the database, even though the rest of the database may not have been reconstructed. Thus, the database has failed to protect this person's privacy even though the attack did not fully reconstruct the database.
Although public Census data tables are drawn from hundreds of millions of American individuals, the Census publishes billions of statistics from those individual responses, so there are still sufficient constraints to narrow down the solution universe enormously.


\section{Methods of Attack}

Here we discuss two approaches for solving the system of constraints that we have developed.
\begin{enumerate}

\item \textbf{Brute Force} - trying every possible combination of solutions.\\

\item \textbf{SAT Solvers} - applying programs that quickly solve Boolean algebra problems.\\

\end{enumerate}

For large data sets such as the U.S. Census, performing a brute-force attack is infeasible due to the fact that the runtime of brute force programs scales exponentially with the number of unknowns.
However, SAT solvers are quite effective because they can reconstruct databases much more quickly than can a brute-force approach. Recent advances in SAT solver heuristics have enabled these programs to frequently solve systems with even millions of variables in a matter of minutes. In later examples, we will use a SAT solver to demonstrate how quickly these very complex programs can solve large systems of equations.

\section{Database Reconstruction with a SAT Solver}

In order to show how a SAT solver can be used to rapidly narrow down the solution universe for a data set, we will perform a mock DRA on a new, larger set of responses to the survey given earlier.

The ground truth responses from two new households are given in Table~\ref{resultsbig}. The statistical agency publishes the statistics in Table~\ref{publishedstatsbig} after processing the ground truth responses.


\begin{table}[t]
\begin{tabular}{c|c|c}
Group & Number & Average Age \\
\hline
Individuals & 10 & 40 \\
Males & 5 & 34 \\
Females & 5 & 46 \\
Whites & 5 & 50 \\
Blacks & 5 & 30 \\
\hline
Children (0-12) & 3 & 10 \\
White children & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Black children & 2 & 10 \\
\hline
Parents & 4 & 32.5 \\
Male parents & 2 & 30 \\
Female parents & 2 & 35 \\
Parents over 40 & 0 & -- \\
\hline
Grandparents & 3 & 80 \\
White grandparents & 2 & 80 \\
Black grandparents & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Male grandparents & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Female grandparents & 2 & 75 \\
\hline
Households & 2 & 40 \\
Tri-generational households & 0 & -- \\
Single-parent households & 0 & -- \\
Childless households & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Interracial married couples & 2 & 32.5 \\
Same-sex married couples & 0 & -- \\
Households $\geq 40\% $ female & 2 & 40 \\
Households $\geq 40\% $ black & 2 & 40 \\

\hline
\end{tabular}
\caption{Data publication. Note that 4 values have been suppressed.}\label{publishedstatsbig}
\end{table}

From this data, the attacker generates many constraint equations as demonstrated earlier,
and then inputs these constraints into a SAT solver. In this example, we use a free open-source SAT solver
called PicoSAT written in C. PicoSAT takes input in the standard DIMACS file format. Because the DIMACS format can be difficult to understand, we use another open source program, Sugar\cite{sugar}, to translate our system of constraints into the DIMACS format. In Sugar, constraints are given to the SAT solver through \textit{s-expressions}, which are mathematical expressions written in a special nested prefix form. For example, the constraint "Average total age (in a population of size 5): 40" is encoded as the following s-expression:
\begin{verbatim}
(= (/ (+ A1 A2 A3 A4 A5) 5) 40)
\end{verbatim}

S-expressions are evaluated from the innermost parentheses to the outermost, with the operator at the left of each parenthetic expression being applied to the rest of the arguments in that expression. The above expression is evaluated using the following steps:
\begin{enumerate}
    \item Take the sum of variables A1...A5.
    \item Divide the result of Step 1 by 5.
    \item The result of Step 2 must equal 40.
\end{enumerate}

Output is given in Table~\ref{sugarbig} and is tabulated for readability. Although the ID numbers are permutated, the ten people in the SAT solver output are identical to the ten people from the ground truth in Table~\ref{resultsbig}, so the attack has succeeded in reconstructing the entire database and narrowing down the solution universe to size 1. Finding this solution required 35 seconds on a single 2012 MacBook Pro with an Intel i7 2.9GHz processor.

At past international SAT solver competitions, SAT solvers such as PicoSAT have solved problems with tens of millions of variables in less than 20 minutes \cite{satcomp}, demonstrating that dataset size and constraint number is not an insurmountable obstacle to this type of DRA.

\begin{table}
\begin{tabular}{c|c|c|c|c|c}
ID & Household & Age & Sex & Race & Generation \\
\hline
1 & 2 & 10 & 1 & 0 & 0  \\
2 & 2 & 20 & 0 & 1 & 1  \\
3 & 1 & 30 & 1 & 1 & 1  \\
4 & 2 & 10 & 0 & 1 & 0  \\
5 & 2 & 40 & 1 & 0 & 1  \\
6 & 2 & 10 & 0 & 1 & 0  \\
7 & 1 & 40 & 0 & 0 & 1  \\
8 & 1 & 80 & 1 & 1 & 2  \\
9 & 1 & 90 & 0 & 0 & 2 \\
10 & 1 & 70 & 1 & 0 & 2 \\
\hline
\end{tabular}
\caption{Sugar output when run on the encoded statistics in Appendix 3}\label{sugarbig}
\end{table}


\section{Defending Against a DRA}
As demonstrated above, new techniques must be developed in
order to protect databases against reconstruction attacks, as traditional techniques such as cell suppression are insufficient defense. One of the simplest and most effective techniques in defending against the DRA is noise infusion, where the publishing agency adds random values to data before publication in order to increase the size of the solution universe. For example, if the statistical agency takes a true value of age = 10, then randomly adds either -2, -1, 0, 1, or 2, and then calculates and publishes statistics consistent with this new age, there are now five elements in the solution universe for this value, where without noise infusion there would be only one. If two responses are processed with noise of this sort, there are now $5^2 = 25$ possible solutions. If 10 people undergo noise infusion of this type, there are $5^{10}$ --- nearly 10 million --- possible solutions. Notice that the statistical agency can reveal that noise infusion has taken place, and can even reveal how much noise has been added, without compromising the effectiveness of said noise infusion. Noise infusion allows an agency to publish more statistics without fearing that it has given attackers too many constraints to work with.

In the following example of noise infusion, we use noise generated
from a distribution called the Laplace distribution
\cite{Dwork:2006:CNS:2180286.2180305}. We choose this distribution
because, when correctly applied, this type of noise addition gives a
strong mathematical guarantee of individual privacy. To demonstrate
how effective adding Laplace noise is against the DRA, we reconsider
the example from the previous section. This time, the statistical
agency applies the Laplace transformation with mean 0 and exponential
decay 3 to the survey responses to the ages before publishing any
statistical products. The new published data product, analogous to
Table~\ref{publishedstatsbig}, is shown in
Table~\ref{publishedstatsnoise}.

\begin{table}[t]
\begin{tabular}{c|c|c}
Group & Number & Average Age \\
\hline
Individuals & 10 & 38.57 \\
Males & 5 & 33.21 \\
Females & 5 & 43.92 \\
Whites & 5 & 47.82 \\
Blacks & 5 & 29.31 \\
\hline
Children (0-12) & 3 & 8.50 \\
White children & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Black children & 2 & 8.75 \\
\hline
Parents & 4 & 31.41 \\
Male parents & 2 & 29.77 \\
Female parents & 2 & 33.06 \\
Parents over 40 & 0 & -- \\
\hline
Grandparents & 3 & 78.18 \\
White grandparents & 2 & 77.64 \\
Black grandparents & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Male grandparents & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Female grandparents & 2 & 72.76 \\
\hline
Households & 2 & 38.57 \\
Tri-generational households & 0 & -- \\
Single-parent households & 0 & -- \\
Childless households & 1 & \multicolumn{1}{c}{\rule{6mm}{3mm}} \\
Interracial married couples & 2 & 31.41 \\
Same-sex married couples & 0 & -- \\
Households $\geq 40\% $ female & 2 & 38.57 \\
Households $\geq 40\% $ black & 2 & 38.57 \\

\hline
\end{tabular}
\caption{Data publication with added Laplace noise}\label{publishedstatsnoise}
\end{table}
It is important to note that the infusion of the noise did not significantly impact the reported statistics, thus preserving their utility to nonintrusive users. However, when the attacker attempts to perform the DRA using the same process as before, Sugar returns "Unsatisfiable". The noise infusion has defeated the DRA, and the statistical agency has upheld its legal obligation to protect respondent privacy.

\section{Problem Analysis}

With the dramatic improvement in the efficiency of SAT solvers in the last decade, the database reconstruction attack is no longer a solely theoretical danger. The vast amount of data products the Census publishes each year gives a determined and informed attacker more than enough constraints to reconstruct some or all of a target database and breach the privacy of millions of people. Although the Census Bureau's current disclosure avoidance technique suite is often sufficient to defend against a cursory attempt at an identification attack, we have demonstrated through attack simulations that cell suppression and grouping are not completely against the power of more sophisticated forms of attack.

The most effective technique for defending against a DRA is the infusion of noise to results before publication. If the noise is generated by correctly applying the Laplace mechanism, it is possible to guarantee individuals' choice to respond to a survey cannot harm them while simultaneously preserving the accuracy of the data for benign use. In infusion to continuing to use the traditional disclosure avoidance techniques, data agencies should make probabilistic noise infusion a required part of the pre-publication disclosure review process in order to protect respondent privacy.

\section{References}

\bibliography{refs}
\bibliographystyle{ieeetr}


\section{Appendices}

\subsection{SAT and SAT Solvers}

The Boolean satisfiability problem, known as SAT, was the first problem to be proven NP-complete \cite{cooklevin}. This problem asks, for a given Boolean formula, whether replacing each variable with either True or False can make the formula evaluate to True.   A consequence of SAT being NP-complete is that any problem can be reduced in polynomial time (i.e., quickly) to an instance of the SAT problem. Once a problem has been reduced to an instance of the SAT problem, this SAT problem can be fed into a SAT solver to find possible solutions. Although the SAT problem is not solvable by algorithms in polynomial time, researchers have found many heuristic techniques for expediting this process. SAT solvers combine a variety of these techniques into one complex process, resulting in polynomial time solutions for the SAT problem in many cases.

Modern SAT solvers use a heuristic technique called Conflict-Driven Clause Learning, commonly referred to as CDCL. CDCL works by the following process \cite{cdcl}:

\begin{enumerate}

\item Assign a value to a variable arbitrarily.
\item Use this assignment to determine values for the other variables in the formula (a process known as unit propagation).
\item If a conflict is found, backtrack to the clause that made the conflict occur and undo variable assignments made after that point.
\item Add the negation of the conflict-causing clause as a new clause to the master formula and resume from step 1.

\end{enumerate}

This process is much faster at solving SAT problems than previous processes used in SAT solvers because adding conflicts as new clauses has the potential to avoid wasteful 'repeated backtracks'. Additionally, CDCL and its predecessor algorithm, DPLL, are both provably complete algorithms and will always return either a solution or "Unsatisfiable" if given enough time and memory.

There are a wide variety of SAT solvers available to the public for minimal or no cost. Although a SAT solver requires the user to translate the problem into Boolean formulae before use,  programs such as Naoyuki Tamura's Sugar facilitate this process by translating user-input mathematical and English constraints into Boolean formulae automatically.



\subsection{Sugar Input}

Sugar input is given in a standard Constraint Satisfaction Problem (CSP) file format. A constraint must be given on a single line of the file, but here we separate most constraints into multiple lines for readability. Constraint equations are separated by comments describing what statistics they encode.

Input for the mock survey from Section 4 is as follows:

\begin{verbatim}
;define variables and their domains
;households (either 1 or 2)
(int H1 1 2)
(int H2 1 2)
(int H3 1 2)
(int H4 1 2)
(int H5 1 2)
(int H6 1 2)
(int H7 1 2)
(int H8 1 2)
(int H9 1 2)
(int H10 1 2)
;ages (between 1 and 90 years old)
(int A1 1 90)
(int A2 1 90)
(int A3 1 90)
(int A4 1 90)
(int A5 1 90)
(int A6 1 90)
(int A7 1 90)
(int A8 1 90)
(int A9 1 90)
(int A10 1 90)
;sexes (male or female)
(int S1 0 1)
(int S2 0 1)
(int S3 0 1)
(int S4 0 1)
(int S5 0 1)
(int S6 0 1)
(int S7 0 1)
(int S8 0 1)
(int S9 0 1)
(int S10 0 1)
;races (white or black)
(int R1 0 1)
(int R2 0 1)
(int R3 0 1)
(int R4 0 1)
(int R5 0 1)
(int R6 0 1)
(int R7 0 1)
(int R8 0 1)
(int R9 0 1)
(int R10 0 1)
;generations (child, parent, or grandparent)
(int G1 0 2)
(int G2 0 2)
(int G3 0 2)
(int G4 0 2)
(int G5 0 2)
(int G6 0 2)
(int G7 0 2)
(int G8 0 2)
(int G9 0 2)
(int G10 0 2)
;
;avg age total
(= (/ (+ A1 A2 A3 A4 A5 A6 A7 A8 A9 A10)
10) 40)
;household sizes
(<= (+ (if (= H1 1) 1 0) (if (= H2 1) 1 0)
(if (= H3 1) 1 0) (if (= H4 1) 1 0)
(if (= H5 1) 1 0) (if (= H6 1) 1 0)
(if (= H7 1) 1 0) (if (= H8 1) 1 0)
(if (= H9 1) 1 0) (if (= H10 1) 1 0) ) 5)
(>= (+ (if (= H1 1) 1 0) (if (= H2 1) 1 0)
(if (= H3 1) 1 0) (if (= H4 1) 1 0)
(if (= H5 1) 1 0) (if (= H6 1) 1 0)
(if (= H7 1) 1 0) (if (= H8 1) 1 0)
(if (= H9 1) 1 0) (if (= H10 1) 1 0) ) 5)
;number of children
(= (+ (if (= G1 0) 1 0) (if (= G2 0) 1 0)
(if (= G3 0) 1 0) (if (= G4 0) 1 0)
(if (= G5 0) 1 0) (if (= G6 0) 1 0)
(if (= G7 0) 1 0) (if (= G8 0) 1 0)
(if (= G9 0) 1 0) (if (= G10 0) 1 0) ) 3)
;number of parents
(= (+ (if (= G1 1) 1 0) (if (= G2 1) 1 0)
(if (= G3 1) 1 0) (if (= G4 1) 1 0)
(if (= G5 1) 1 0) (if (= G6 1) 1 0)
(if (= G7 1) 1 0) (if (= G8 1) 1 0)
(if (= G9 1) 1 0) (if (= G10 1) 1 0) ) 4)
;number of grandparents
(= (+ (if (= G1 2) 1 0) (if (= G2 2) 1 0)
(if (= G3 2) 1 0) (if (= G4 2) 1 0)
(if (= G5 2) 1 0) (if (= G6 2) 1 0)
(if (= G7 2) 1 0) (if (= G8 2) 1 0)
(if (= G9 2) 1 0) (if (= G10 2) 1 0) ) 3)
;number of males
(= (+ (if (= S1 0) 1 0) (if (= S2 0) 1 0)
(if (= S3 0) 1 0) (if (= S4 0) 1 0)
(if (= S5 0) 1 0) (if (= S6 0) 1 0)
(if (= S7 0) 1 0) (if (= S8 0) 1 0)
(if (= S9 0) 1 0) (if (= S10 0) 1 0) ) 5)
;number of females
(= (+ (if (= S1 1) 1 0) (if (= S2 1) 1 0)
(if (= S3 1) 1 0) (if (= S4 1) 1 0)
(if (= S5 1) 1 0) (if (= S6 1) 1 0)
(if (= S7 1) 1 0) (if (= S8 1) 1 0)
(if (= S9 1) 1 0) (if (= S10 1) 1 0) ) 5)
;number of blacks
(= (+ (if (= R1 1) 1 0) (if (= R2 1) 1 0)
(if (= R3 1) 1 0) (if (= R4 1) 1 0)
(if (= R5 1) 1 0) (if (= R6 1) 1 0)
(if (= R7 1) 1 0) (if (= R8 1) 1 0)
(if (= R9 1) 1 0) (if (= R10 1) 1 0) ) 5)
;number of whites
(= (+ (if (= R1 0) 1 0) (if (= R2 0) 1 0)
(if (= R3 0) 1 0) (if (= R4 0) 1 0)
(if (= R5 0) 1 0) (if (= R6 0) 1 0)
(if (= R7 0) 1 0) (if (= R8 0) 1 0)
(if (= R9 0) 1 0) (if (= R10 0) 1 0) ) 5)
;avg age blacks
(= (/ (* (+ (* A1 (if (= R1 1) 1 0))
(* A2 (if (= R2 1) 1 0))
(* A3 (if (= R3 1) 1 0))
(* A4 (if (= R4 1) 1 0))
(* A5 (if (= R5 1) 1 0))
(* A6 (if (= R6 1) 1 0))
(* A7 (if (= R7 1) 1 0))
(* A8 (if (= R8 1) 1 0))
(* A9 (if (= R9 1) 1 0))
(* A10 (if (= R10 1) 1 0))) 10) 5) 300)
;avg age whites
(= (/ (* (+ (* A1 (if (= R1 0) 1 0))
(* A2 (if (= R2 0) 1 0))
(* A3 (if (= R3 0) 1 0))
(* A4 (if (= R4 0) 1 0))
(* A5 (if (= R5 0) 1 0))
(* A6 (if (= R6 0) 1 0))
(* A7 (if (= R7 0) 1 0))
(* A8 (if (= R8 0) 1 0))
(* A9 (if (= R9 0) 1 0))
(* A10 (if (= R10 0) 1 0)))  10) 5) 500)
;avg age children
(= (/ (* (+ (* A1 (if (= G1 0) 1 0))
(* A2 (if (= G2 0) 1 0))
(* A3 (if (= G3 0) 1 0))
(* A4 (if (= G4 0) 1 0))
(* A5 (if (= G5 0) 1 0))
(* A6 (if (= G6 0) 1 0))
(* A7 (if (= G7 0) 1 0))
(* A8 (if (= G8 0) 1 0))
(* A9 (if (= G9 0) 1 0))
(* A10 (if (= G10 0) 1 0)) ) 10) 3) 100)
;avg age parents
(= (/ (* (+ (* A1 (if (= G1 1) 1 0))
(* A2 (if (= G2 1) 1 0))
(* A3 (if (= G3 1) 1 0))
(* A4 (if (= G4 1) 1 0))
(* A5 (if (= G5 1) 1 0))
(* A6 (if (= G6 1) 1 0))
(* A7 (if (= G7 1) 1 0))
(* A8 (if (= G8 1) 1 0))
(* A9 (if (= G9 1) 1 0))
(* A10 (if (= G10 1) 1 0))) 10) 4) 325)
;avg age grandparents
(= (/ (* (+ (* A1 (if (= G1 2) 1 0))
(* A2 (if (= G2 2) 1 0))
(* A3 (if (= G3 2) 1 0))
(* A4 (if (= G4 2) 1 0))
(* A5 (if (= G5 2) 1 0))
(* A6 (if (= G6 2) 1 0))
(* A7 (if (= G7 2) 1 0))
(* A8 (if (= G8 2) 1 0))
(* A9 (if (= G9 2) 1 0))
(* A10 (if (= G10 2) 1 0)) ) 10) 3) 800)
;avg age males
(= (/ (* (+ (* A1 (if (= S1 0) 1 0))
(* A2 (if (= S2 0) 1 0))
(* A3 (if (= S3 0) 1 0))
(* A4 (if (= S4 0) 1 0))
(* A5 (if (= S5 0) 1 0))
(* A6 (if (= S6 0) 1 0))
(* A7 (if (= S7 0) 1 0))
(* A8 (if (= S8 0) 1 0))
(* A9 (if (= S9 0) 1 0))
(* A10 (if (= S10 0) 1 0)) ) 10) 5) 340)
;avg age females
(= (/ (* (+ (* A1 (if (= S1 1) 1 0))
(* A2 (if (= S2 1) 1 0))
(* A3 (if (= S3 1) 1 0))
(* A4 (if (= S4 1) 1 0))
(* A5 (if (= S5 1) 1 0))
(* A6 (if (= S6 1) 1 0))
(* A7 (if (= S7 1) 1 0))
(* A8 (if (= S8 1) 1 0))
(* A9 (if (= S9 1) 1 0))
(* A10 (if (= S10 1) 1 0)) ) 10) 5) 460)
;number of households
(nvalue 2 (H1 H2 H3 H4 H5 H6 H7 H8 H9 H10))
;number of male children
(= (+ (if (and (= G1 0) (= S1 0 )) 1 0)
(if (and (= G2 0) (= S2 0 )) 1 0)
(if (and (= G3 0) (= S3 0 )) 1 0)
(if (and (= G4 0) (= S4 0 )) 1 0)
(if (and (= G5 0) (= S5 0 )) 1 0)
(if (and (= G6 0) (= S6 0 )) 1 0)
(if (and (= G7 0) (= S7 0 )) 1 0)
(if (and (= G8 0) (= S8 0 )) 1 0)
(if (and (= G9 0) (= S9 0 )) 1 0)
(if (and (= G10 0) (= S10 0 )) 1 0) ) 2)
;number of female children
(= (+ (if (and (= G1 0) (= S1 1 )) 1 0)
(if (and (= G2 0) (= S2 1 )) 1 0)
(if (and (= G3 0) (= S3 1 )) 1 0)
(if (and (= G4 0) (= S4 1 )) 1 0)
(if (and (= G5 0) (= S5 1 )) 1 0)
(if (and (= G6 0) (= S6 1 )) 1 0)
(if (and (= G7 0) (= S7 1 )) 1 0)
(if (and (= G8 0) (= S8 1 )) 1 0)
(if (and (= G9 0) (= S9 1 )) 1 0)
(if (and (= G10 0) (= S10 1 )) 1 0) ) 1)
;number of children 0-12: 3
(= (+ (if (and (>= A1 1) (<= A1 12)) 1 0)
(if (and (>= A2 1) (<= A2 12)) 1 0)
(if (and (>= A3 1) (<= A3 12)) 1 0)
(if (and (>= A4 1) (<= A4 12)) 1 0)
(if (and (>= A5 1) (<= A5 12)) 1 0)
(if (and (>= A6 1) (<= A6 12)) 1 0)
(if (and (>= A7 1) (<= A7 12)) 1 0)
(if (and (>= A8 1) (<= A8 12)) 1 0)
(if (and (>= A9 1) (<= A9 12)) 1 0)
(if (and (>= A10 1) (<= A10 12)) 1 0) ) 3)
;number of children 13-17: 0
(= (+ (if (and (>= A1 13) (<= A1 17)) 1 0)
(if (and (>= A2 13) (<= A2 17)) 1 0)
(if (and (>= A3 13) (<= A3 17)) 1 0)
(if (and (>= A4 13) (<= A4 17)) 1 0)
(if (and (>= A5 13) (<= A5 17)) 1 0)
(if (and (>= A6 13) (<= A6 17)) 1 0)
(if (and (>= A7 13) (<= A7 17)) 1 0)
(if (and (>= A8 13) (<= A8 17)) 1 0)
(if (and (>= A9 13) (<= A9 17)) 1 0)
(if (and (>= A10 13) (<= A10 17)) 1 0) ) 0)
;avg age of children 0-12: 10
(= (/ (* (+
(* A1 (if (and (>= A1 1) (<= A1 12)) 1 0))
(* A2 (if (and (>= A2 1) (<= A2 12)) 1 0))
(* A3 (if (and (>= A3 1) (<= A3 12)) 1 0))
(* A4 (if (and (>= A4 1) (<= A4 12)) 1 0))
(* A5 (if (and (>= A5 1) (<= A5 12)) 1 0))
(* A6 (if (and (>= A6 1) (<= A6 12)) 1 0))
(* A7 (if (and (>= A7 1) (<= A7 12)) 1 0))
(* A8 (if (and (>= A8 1) (<= A8 12)) 1 0))
(* A9 (if (and (>= A9 1) (<= A9 12)) 1 0))
(* A10 (if (and (>= A10 1) (<= A10 12)) 1 0)))
10) 3) 100)
;number of hh with 3 or more generations: 1
(xor (nvalue 3 (G1 G2 G3 G4 G5))
(nvalue 3(G6 G7 G8 G9 G10)))
;number of male parents
(= (+ (if (and (= G1 1) (= S1 0 )) 1 0)
(if (and (= G2 1) (= S2 0 )) 1 0)
(if (and (= G3 1) (= S3 0 )) 1 0)
(if (and (= G4 1) (= S4 0 )) 1 0)
(if (and (= G5 1) (= S5 0 )) 1 0)
(if (and (= G6 1) (= S6 0 )) 1 0)
(if (and (= G7 1) (= S7 0 )) 1 0)
(if (and (= G8 1) (= S8 0 )) 1 0)
(if (and (= G9 1) (= S9 0 )) 1 0)
(if (and (= G10 1) (= S10 0 )) 1 0) ) 2)
;number of female parents
(= (+ (if (and (= G1 1) (= S1 1 )) 1 0)
(if (and (= G2 1) (= S2 1 )) 1 0)
(if (and (= G3 1) (= S3 1 )) 1 0)
(if (and (= G4 1) (= S4 1 )) 1 0)
(if (and (= G5 1) (= S5 1 )) 1 0)
(if (and (= G6 1) (= S6 1 )) 1 0)
(if (and (= G7 1) (= S7 1 )) 1 0)
(if (and (= G8 1) (= S8 1 )) 1 0)
(if (and (= G9 1) (= S9 1 )) 1 0)
(if (and (= G10 1) (= S10 1 )) 1 0) ) 2)
;number of single-parent households: 0
(< (+ (if (and (= H1 1) (= G1 1)) 1 0)
(if (and (= H2 1) (= G2 1)) 1 0)
(if (and (= H3 1) (= G3 1)) 1 0)
(if (and (= H4 1) (= G4 1)) 1 0)
(if (and (= H5 1) (= G5 1)) 1 0)
(if (and (= H6 1) (= G6 1)) 1 0)
(if (and (= H7 1) (= G7 1)) 1 0)
(if (and (= H8 1) (= G8 1)) 1 0)
(if (and (= H9 1) (= G9 1)) 1 0)
(if (and (= H10 1) (= G10 1)) 1 0) ) 3)
(< (+ (if (and (= H1 2) (= G1 1)) 1 0)
(if (and (= H2 2) (= G2 1)) 1 0)
(if (and (= H3 2) (= G3 1)) 1 0)
(if (and (= H4 2) (= G4 1)) 1 0)
(if (and (= H5 2) (= G5 1)) 1 0)
(if (and (= H6 2) (= G6 1)) 1 0)
(if (and (= H7 2) (= G7 1)) 1 0)
(if (and (= H8 2) (= G8 1)) 1 0)
(if (and (= H9 2) (= G9 1)) 1 0)
(if (and (= H10 2) (= G10 1)) 1 0) ) 3)
;total number of black children: 2
(= (+ (if (and (= G1 0) (= R1 1)) 1 0)
(if (and (= G2 0) (= R2 1)) 1 0)
(if (and (= G3 0) (= R3 1)) 1 0)
(if (and (= G4 0) (= R4 1)) 1 0)
(if (and (= G5 0) (= R5 1)) 1 0)
(if (and (= G6 0) (= R6 1)) 1 0)
(if (and (= G7 0) (= R7 1)) 1 0)
(if (and (= G8 0) (= R8 1)) 1 0)
(if (and (= G9 0) (= R9 1)) 1 0)
(if (and (= G10 0) (= R10 1)) 1 0) ) 2)
;total number of black females: 2
(= (+ (if (and (= S1 1) (= R1 1)) 1 0)
(if (and (= S2 1) (= R2 1)) 1 0)
(if (and (= S3 1) (= R3 1)) 1 0)
(if (and (= S4 1) (= R4 1)) 1 0)
(if (and (= S5 1) (= R5 1)) 1 0)
(if (and (= S6 1) (= R6 1)) 1 0)
(if (and (= S7 1) (= R7 1)) 1 0)
(if (and (= S8 1) (= R8 1)) 1 0)
(if (and (= S9 1) (= R9 1)) 1 0)
(if (and (= S10 1) (= R10 1)) 1 0) ) 2)
;all households are at least 40% minority
(>= (+ (if (and (= H1 1) (= R1 1)) 1 0)
(if (and (= H2 1) (= R2 1)) 1 0)
(if (and (= H3 1) (= R3 1)) 1 0)
(if (and (= H4 1) (= R4 1)) 1 0)
(if (and (= H5 1) (= R5 1)) 1 0)
(if (and (= H6 1) (= R6 1)) 1 0)
(if (and (= H7 1) (= R7 1)) 1 0)
(if (and (= H8 1) (= R8 1)) 1 0)
(if (and (= H9 1) (= R9 1)) 1 0)
(if (and (= H10 1) (= R10 1)) 1 0) ) 2)
(>= (+ (if (and (= H1 2) (= R1 1)) 1 0)
(if (and (= H2 2) (= R2 1)) 1 0)
(if (and (= H3 2) (= R3 1)) 1 0)
(if (and (= H4 2) (= R4 1)) 1 0)
(if (and (= H5 2) (= R5 1)) 1 0)
(if (and (= H6 2) (= R6 1)) 1 0)
(if (and (= H7 2) (= R7 1)) 1 0)
(if (and (= H8 2) (= R8 1)) 1 0)
(if (and (= H9 2) (= R9 1)) 1 0)
(if (and (= H10 2) (= R10 1)) 1 0) ) 2)
;all households are at least 40% female
(>= (+ (if (and (= H1 1) (= S1 1)) 1 0)
(if (and (= H2 1) (= S2 1)) 1 0)
(if (and (= H3 1) (= S3 1)) 1 0)
(if (and (= H4 1) (= S4 1)) 1 0)
(if (and (= H5 1) (= S5 1)) 1 0)
(if (and (= H6 1) (= S6 1)) 1 0)
(if (and (= H7 1) (= S7 1)) 1 0)
(if (and (= H8 1) (= S8 1)) 1 0)
(if (and (= H9 1) (= S9 1)) 1 0)
(if (and (= H10 1) (= S10 1)) 1 0) ) 2)
(>= (+ (if (and (= H1 2) (= S1 1)) 1 0)
(if (and (= H2 2) (= S2 1)) 1 0)
(if (and (= H3 2) (= S3 1)) 1 0)
(if (and (= H4 2) (= S4 1)) 1 0)
(if (and (= H5 2) (= S5 1)) 1 0)
(if (and (= H6 2) (= S6 1)) 1 0)
(if (and (= H7 2) (= S7 1)) 1 0)
(if (and (= H8 2) (= S8 1)) 1 0)
(if (and (= H9 2) (= S9 1)) 1 0)
(if (and (= H10 2) (= S10 1)) 1 0) ) 2)
;number of households with
same-sex married couples: 0
(= 1 (+ (if (and (= H1 1)
    (and (= G1 1) (= S1 0))) 1 0)
(if (and (= H2 1)
    (and (= G2 1) (= S2 0))) 1 0)
(if (and (= H3 1)
    (and (= G3 1) (= S3 0))) 1 0)
(if (and (= H4 1)
    (and (= G4 1) (= S4 0))) 1 0)
(if (and (= H5 1)
    (and (= G5 1) (= S5 0))) 1 0)
(if (and (= H6 1)
    (and (= G6 1) (= S6 0))) 1 0)
(if (and (= H7 1)
    (and (= G7 1) (= S7 0))) 1 0)
(if (and (= H8 1)
    (and (= G8 1) (= S8 0))) 1 0)
(if (and (= H9 1)
    (and (= G9 1) (= S9 0))) 1 0)
(if (and (= H10 1)
    (and (= G10 1) (= S10 0))) 1 0)))
(= 1 (+ (if (and (= H1 2)
   (and (= G1 1) (= S1 0))) 1 0)
(if (and (= H2 2)
   (and (= G2 1) (= S2 0))) 1 0)
(if (and (= H3 2)
   (and (= G3 1) (= S3 0))) 1 0)
(if (and (= H4 2)
   (and (= G4 1) (= S4 0))) 1 0)
(if (and (= H5 2)
   (and (= G5 1) (= S5 0))) 1 0)
(if (and (= H6 2)
   (and (= G6 1) (= S6 0))) 1 0)
(if (and (= H7 2)
   (and (= G7 1) (= S7 0))) 1 0)
(if (and (= H8 2)
   (and (= G8 1) (= S8 0))) 1 0)
(if (and (= H9 2)
   (and (= G9 1) (= S9 0))) 1 0)
(if (and (= H10 2)
   (and (= G10 1) (= S10 0))) 1 0)))
;avg age of male parents: 30
(= (/ (* (+ (* (if (and (= G1 1)
(= S1 0)) 1 0) A1)
(* (if (and (= G2 1)
(= S2 0)) 1 0) A2)
(* (if (and (= G3 1)
(= S3 0)) 1 0) A3)
(* (if (and (= G4 1)
(= S4 0)) 1 0) A4)
(* (if (and (= G5 1)
(= S5 0)) 1 0) A5)
(* (if (and (= G6 1)
(= S6 0)) 1 0) A6)
(* (if (and (= G7 1)
(= S7 0)) 1 0) A7)
(* (if (and (= G8 1)
(= S8 0)) 1 0) A8)
(* (if (and (= G9 1)
(= S9 0)) 1 0) A9)
(* (if (and (= G10 1)
(= S10 0)) 1 0) A10)) 10) 2) 300)
;avg age of female parents: 35
(= (/ (* (+ (* (if (and (= G1 1)
   (= S1 1)) 1 0) A1)
(* (if (and (= G2 1)
   (= S2 1)) 1 0) A2)
(* (if (and (= G3 1)
   (= S3 1)) 1 0) A3)
(* (if (and (= G4 1)
   (= S4 1)) 1 0) A4)
(* (if (and (= G5 1)
   (= S5 1)) 1 0) A5)
(* (if (and (= G6 1)
   (= S6 1)) 1 0) A6)
(* (if (and (= G7 1)
   (= S7 1)) 1 0) A7)
(* (if (and (= G8 1)
   (= S8 1)) 1 0) A8)
(* (if (and (= G9 1)
   (= S9 1)) 1 0) A9)
(* (if (and (= G10 1)
   (= S10 1)) 1 0) A10)) 10) 2) 350)
;avg age of female grandparents: 75
(= (/ (* (+ (* (if (and (= G1 2)
(= S1 1)) 1 0) A1)
(* (if (and (= G2 2) (= S2 1)) 1 0) A2)
(* (if (and (= G3 2) (= S3 1)) 1 0) A3)
(* (if (and (= G4 2) (= S4 1)) 1 0) A4)
(* (if (and (= G5 2) (= S5 1)) 1 0) A5)
(* (if (and (= G6 2) (= S6 1)) 1 0) A6)
(* (if (and (= G7 2) (= S7 1)) 1 0) A7)
(* (if (and (= G8 2) (= S8 1)) 1 0) A8)
(* (if (and (= G9 2) (= S9 1)) 1 0) A9)
(* (if (and (= G10 2) (= S10 1)) 1 0) A10))
10) 2) 750)
;number of parents over 40: 0
(= 0 (+ (if (and(= G1 1) (> A1 40)) 1 0)
(if (and(= G2 1) (> A2 40)) 1 0)
(if (and(= G3 1) (> A3 40)) 1 0)
(if (and(= G4 1) (> A4 40)) 1 0)
(if (and(= G5 1) (> A5 40)) 1 0)
(if (and(= G6 1) (> A6 40)) 1 0)
(if (and(= G7 1) (> A7 40)) 1 0)
(if (and(= G8 1) (> A8 40)) 1 0)
(if (and(= G9 1) (> A9 40)) 1 0)
(if (and(= G10 1) (> A10 40)) 1 0)))
;number of children over 10: 0
(= 0 (+ (if (and (= G1 0) (> A1 10)) 1 0)
(if (and (= G2 0) (> A2 10)) 1 0)
(if (and (= G3 0) (> A3 10)) 1 0)
(if (and (= G4 0) (> A4 10)) 1 0)
(if (and (= G5 0) (> A5 10)) 1 0)
(if (and (= G6 0) (> A6 10)) 1 0)
(if (and (= G7 0) (> A7 10)) 1 0)
(if (and (= G8 0) (> A8 10)) 1 0)
(if (and (= G9 0) (> A9 10)) 1 0)
(if (and (= G10 0) (> A10 10)) 1 0)) )
;number of female grandparents: 2
(= (+ (if (and (= G1 2) (= S1 1 )) 1 0)
(if (and (= G2 2) (= S2 1 )) 1 0)
(if (and (= G3 2) (= S3 1 )) 1 0)
(if (and (= G4 2) (= S4 1 )) 1 0)
(if (and (= G5 2) (= S5 1 )) 1 0)
(if (and (= G6 2) (= S6 1 )) 1 0)
(if (and (= G7 2) (= S7 1 )) 1 0)
(if (and (= G8 2) (= S8 1 )) 1 0)
(if (and (= G9 2) (= S9 1 )) 1 0)
(if (and (= G10 2) (= S10 1 )) 1 0) ) 2)
;avg age white grandparents: 80
(= (/ (* (+ (* (if (and (= G1 2)
(= R1 0)) 1 0) A1)
(* (if (and (= G2 2) (= R2 0)) 1 0) A2)
(* (if (and (= G3 2) (= R3 0)) 1 0) A3)
(* (if (and (= G4 2) (= R4 0)) 1 0) A4)
(* (if (and (= G5 2) (= R5 0)) 1 0) A5)
(* (if (and (= G6 2) (= R6 0)) 1 0) A6)
(* (if (and (= G7 2) (= R7 0)) 1 0) A7)
(* (if (and (= G8 2) (= R8 0)) 1 0) A8)
(* (if (and (= G9 2) (= R9 0)) 1 0) A9)
(* (if (and (= G10 2) (= R10 0)) 1 0) A10))
10) 2) 800)
;number of childless households: 1
(xor (= (+ (if (and (= H1 1) (= G1 0)) 1 0)
(if (and (= H2 1) (= G2 0)) 1 0)
(if (and (= H3 1) (= G3 0)) 1 0)
(if (and (= H4 1) (= G4 0)) 1 0)
(if (and (= H5 1) (= G5 0)) 1 0)
(if (and (= H6 1) (= G6 0)) 1 0)
(if (and (= H7 1) (= G7 0)) 1 0)
(if (and (= H8 1) (= G8 0)) 1 0)
(if (and (= H9 1) (= G9 0)) 1 0)
(if (and (= H10 1) (= G10 0)) 1 0) ) 3)
(= (+ (if (and (= H1 2) (= G1 0)) 1 0)
(if (and (= H2 2) (= G2 0)) 1 0)
(if (and (= H3 2) (= G3 0)) 1 0)
(if (and (= H4 2) (= G4 0)) 1 0)
(if (and (= H5 2) (= G5 0)) 1 0)
(if (and (= H6 2) (= G6 0)) 1 0)
(if (and (= H7 2) (= G7 0)) 1 0)
(if (and (= H8 2) (= G8 0)) 1 0)
(if (and (= H9 2) (= G9 0)) 1 0)
(if (and (= H10 2) (= G10 0)) 1 0) ) 3))
;number of interracial married couples: 2
(= 1 (+ (if (and (= H1 1)
   (and (= G1 1) (= R1 0))) 1 0)
(if (and (= H2 1) (and (= G2 1)
   (= R2 0))) 1 0)
(if (and (= H3 1) (and (= G3 1)
   (= R3 0))) 1 0)
(if (and (= H4 1) (and (= G4 1)
   (= R4 0))) 1 0)
(if (and (= H5 1) (and (= G5 1)
   (= R5 0))) 1 0)
(if (and (= H6 1) (and (= G6 1)
   (= R6 0))) 1 0)
(if (and (= H7 1) (and (= G7 1)
   (= R7 0))) 1 0)
(if (and (= H8 1) (and (= G8 1)
   (= R8 0))) 1 0)
(if (and (= H9 1) (and (= G9 1)
   (= R9 0))) 1 0)
(if (and (= H10 1) (and (= G10 1)
   (= R10 0))) 1 0)))
(= 1 (+ (if (and (= H1 2)
   (and (= G1 1) (= R1 0))) 1 0)
(if (and (= H2 2)
   (and (= G2 1) (= R2 0))) 1 0)
(if (and (= H3 2)
   (and (= G3 1) (= R3 0))) 1 0)
(if (and (= H4 2)
   (and (= G4 1) (= R4 0))) 1 0)
(if (and (= H5 2)
   (and (= G5 1) (= R5 0))) 1 0)
(if (and (= H6 2)
   (and (= G6 1) (= R6 0))) 1 0)
(if (and (= H7 2)
   (and (= G7 1) (= R7 0))) 1 0)
(if (and (= H8 2)
   (and (= G8 1) (= R8 0))) 1 0)
(if (and (= H9 2)
   (and (= G9 1) (= R9 0))) 1 0)
(if (and (= H10 2)
   (and (= G10 1) (= R10 0))) 1 0)))
;household average ages: 62, 18
(= 620 (/ (* 10 (+
(* A1 (if (= H1 1) 1 0))
(* A2 (if (= H2 1) 1 0))
(* A3 (if (= H3 1) 1 0))
(* A4 (if (= H4 1) 1 0))
(* A5 (if (= H5 1) 1 0))
(* A6 (if (= H6 1) 1 0))
(* A7 (if (= H7 1) 1 0))
(* A8 (if (= H8 1) 1 0))
(* A9 (if (= H9 1) 1 0))
(* A10 (if (= H10 1) 1 0)))) 5))

\end{verbatim}


\end{document}
